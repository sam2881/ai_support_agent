from typing import Dict, Any
import logging
from datetime import datetime

from agent.clients.github_client import GitHubClient
from agent.clients.airflow_client import AirflowClient
from agent.workflows.config import settings # Import settings for repository details

logger = logging.getLogger(__name__)

def notify_on_failure(context: Dict[str, Any]):
    """
    Triggered by Airflow task failure. This function extracts relevant metadata
    from the Airflow context, fetches additional logs, and creates a GitHub issue
    for triage and automated remediation by the AI agent.

    Args:
        context (Dict[str, Any]): The context dictionary provided by Airflow's
                                   on_failure_callback. Expected to contain keys
                                   like 'dag', 'task_instance', 'dag_run', 'exception', 'ts'.
    """
    logger.info("üõ†Ô∏è `notify_on_failure` triggered from Airflow.")

    dag_id = None
    task_id = None
    dag_run_id = None
    exception_message = "No exception provided."
    timestamp = str(datetime.utcnow())
    
    try:
        dag_id = context["dag"].dag_id
        task_id = context["task_instance"].task_id
        dag_run_id = context["dag_run"].run_id
        exception_message = str(context.get("exception", "No exception provided"))
        timestamp = context.get("ts", str(datetime.utcnow()))
        logger.info(f"Identified failure in DAG: `{dag_id}`, Task: `{task_id}`, Run: `{dag_run_id}`.")
    except KeyError as e:
        logger.error(f"‚ùå Missing expected key in Airflow context: {e}. Cannot fully identify failure details.", exc_info=True)
        # Continue with partial info if critical keys are missing
    except Exception as e:
        logger.error(f"‚ùå Unexpected error parsing Airflow context: {e}", exc_info=True)
        # Continue with partial info

    af_client = AirflowClient()
    gh_client = GitHubClient() # Initialize GitHubClient without repo_owner/name, assumes it uses settings internally

    log_data: Dict[str, str] = {
        "full_log": "",
        "container_id": "Unavailable",
        "traceback": "Log retrieval failed.",
        "error_summary": exception_message,
        "log_tail": "No tail available."
    }

    if dag_id and task_id and dag_run_id:
        try:
            fetched_log_data = af_client.get_task_logs(dag_id, dag_run_id, task_id)
            # Update log_data with fetched information, ensuring all keys exist
            log_data.update({
                "full_log": fetched_log_data.get("log", ""),
                "container_id": fetched_log_data.get("container_id", "Unavailable"),
                "traceback": fetched_log_data.get("traceback", "No traceback available."),
                "error_summary": fetched_log_data.get("error_summary", exception_message),
                "log_tail": fetched_log_data.get("log_tail", "No log tail available.")
            })
            logger.info(f"Successfully fetched logs for `{dag_id}.{task_id}`.")
        except Exception as log_err:
            logger.error(f"‚ùå Error fetching logs for DAG `{dag_id}`, Task `{task_id}`: {log_err}", exc_info=True)
            # log_data remains with default/fallback values if log fetching fails

    # Construct GitHub issue title and body
    title = f"üî• DAG `{dag_id or 'Unknown'}` failed on task `{task_id or 'Unknown'}` [Run: {dag_run_id or 'N/A'}]"
    body = f"""
### ‚ùå DAG Task Failure Report

- **DAG ID:** `{dag_id or 'N/A'}`
- **Task ID:** `{task_id or 'N/A'}`
- **Run ID:** `{dag_run_id or 'N/A'}`
- **Failure Timestamp:** `{timestamp}`
- **Container Host ID:** `{log_data['container_id']}`

---

### üí• Exception Raised

{exception_message}

---

### üìÑ Full Traceback

{log_data['traceback']}

---

### üìã Log Snippet (Last Lines)

{log_data['log_tail']}

---

### üîç Error Summary
- **Final Error Line:** `{log_data['error_summary']}`

---

This issue was auto-generated by the AI Support Agent from Airflow logs.
"""

    try:
        # Assuming create_issue uses settings.REPO_OWNER and settings.REPO_NAME internally
        issue = gh_client.create_issue(
            title=title,
            body=body,
            labels=["airflow", "auto-generated", "needs-triage"] # Added "needs-triage"
        )

        if issue:
            logger.info(f"‚úÖ GitHub issue created: #{issue.number}")
            # Optionally, add a comment with a link to the Airflow task instance if available
            airflow_ui_url = f"{settings.AIRFLOW_BASE_URL}/task-instances/list/?dag_id={dag_id}&task_id={task_id}&run_id={dag_run_id}" if dag_id and task_id and dag_run_id else "#"
            comment = f"üîó View this task instance in Airflow UI: [Link]({airflow_ui_url})"
            gh_client.add_comment(issue.number, comment)
        else:
            logger.warning("‚ö†Ô∏è GitHub issue creation returned None. Issue might not have been created.")
    except Exception as issue_err:
        logger.error(f"‚ùå GitHub issue creation failed: {issue_err}", exc_info=True)
        # Log the full body in case of failure to help debug
        logger.debug(f"Failed issue body: {body}")

    logger.info("üèÅ `notify_on_failure` finished.")

# Example usage (for testing purposes, would typically be called by Airflow)
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    # Mock settings if running directly
    class MockSettings:
        AIRFLOW_BASE_URL = "http://localhost:8080"
        REPO_OWNER = "your-github-user"
        REPO_NAME = "your-repo"
        # Add other necessary settings here, e.g., for GitHubClient init

    # Assign mock settings to the actual settings object
    settings = MockSettings()

    logger.info("Simulating Airflow task failure notification...")

    # Mock Airflow context for a failed task
    mock_airflow_context = {
        "dag": type('MockDag', (object,), {'dag_id': 'my_test_dag'})(),
        "task_instance": type('MockTaskInstance', (object,), {'task_id': 'failing_task'})(),
        "dag_run": type('MockDagRun', (object,), {'run_id': 'manual__2025-05-22T08:00:00+00:00'})(),
        "exception": "Simulated RuntimeError: Data processing failed due to null values.",
        "ts": "2025-05-22T08:05:00Z"
    }

    # Mock AirflowClient's get_task_logs response
    class MockAirflowClient:
        def get_task_logs(self, dag_id, dag_run_id, task_id):
            return {
                "log": "Simulated full log content...\nLine 1\nLine 2\nERROR - RuntimeError: Data processing failed due to null values.\nAt /app/transform.py:123\nMore error details.",
                "container_id": "container-xyz-123",
                "traceback": "Traceback (most recent call last):\n  File \"/usr/local/airflow/dags/my_test_dag.py\", line 45, in failing_task\n    raise RuntimeError(\"Data processing failed due to null values.\")\nRuntimeError: Data processing failed due to null values.",
                "error_summary": "RuntimeError: Data processing failed due to null values.",
                "log_tail": "Line X\nLine Y\nLine Z\nERROR - RuntimeError: Data processing failed due to null values.\nAt /app/transform.py:123"
            }
            
    # Temporarily patch AirflowClient and GitHubClient for testing
    original_airflow_client = AirflowClient
    original_github_client = GitHubClient
    
    AirflowClient = MockAirflowClient
    
    class MockGitHubClient:
        def create_issue(self, title, body, labels):
            logger.info(f"Mock GitHub: Creating issue with title: '{title}' and labels: {labels}")
            class MockIssue:
                def __init__(self, number, title, body, labels):
                    self.number = number
                    self.title = title
                    self.body = body
                    self.labels = labels
            return MockIssue(1234, title, body, labels)
        
        def add_comment(self, issue_number, comment_body):
            logger.info(f"Mock GitHub: Adding comment to issue #{issue_number}: '{comment_body}'")

    GitHubClient = MockGitHubClient

    try:
        notify_on_failure(mock_airflow_context)
    except Exception as e:
        logger.error(f"Error during simulation: {e}")
    finally:
        # Restore original classes
        AirflowClient = original_airflow_client
        GitHubClient = original_github_client

    logger.info("Simulation complete.")